{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load the model\n",
    "model = tf.keras.models.load_model('unet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# load the test data\n",
    "import os\n",
    "\n",
    "data_dir = 'data'\n",
    "mask_dir = \"external_contours_masks\"\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_masks_dir = os.path.join(mask_dir, 'test')\n",
    "train_masks_dir = os.path.join(mask_dir, 'train')\n",
    "\n",
    "# Create a folder with results and subfolders for cropped images, heatmaps and dijkstra\n",
    "results_dir = 'external_contours_masks/results'\n",
    "cropped_dir = os.path.join(results_dir, 'cropped')\n",
    "heatmaps_dir = os.path.join(results_dir, 'heatmaps')\n",
    "dijkstra_dir = os.path.join(results_dir, 'dijkstra')\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "    os.mkdir(cropped_dir)\n",
    "    os.mkdir(heatmaps_dir)\n",
    "    os.mkdir(dijkstra_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "# run over the test data and predict the masks\n",
    "# Find the contour of the mask\n",
    "# Crop the image according to the contour\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_contour(mask: np.ndarray):\n",
    "     # Apply thresholding\n",
    "    ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    # sDefine structuring element (MORPH_RECT)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "    # Erosion using MORPH_RECT structuring element\n",
    "    erosion= cv2.erode(thresh, kernel, iterations=1)\n",
    "    # Dilate using MORPH_RECT structuring element\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations=1)\n",
    "    # Find contour using the eroded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Find the contour with the largest area\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    return contour\n",
    "\n",
    "def crop_image(img, contour):\n",
    "    # Resize the contour to the original image size from 128x128 to 4096x4096\n",
    "    # Add erosion to the contour to make sure the mask will cover the whole tumor\n",
    "    contour = 32 * contour\n",
    "    # Create a mask with the contour\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    # Apply the mask to the image\n",
    "    img = cv2.bitwise_and(img, mask)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_mask(img):\n",
    "    # Predict the mask\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = img / 255\n",
    "    pred = model.predict(img)\n",
    "    pred = tf.argmax(pred, axis=-1)\n",
    "    pred = pred[..., tf.newaxis]\n",
    "    pred = tf.squeeze(pred)\n",
    "    pred = pred.numpy()\n",
    "    pred = pred.astype(np.uint8) * 255\n",
    "    return pred\n",
    "\n",
    "def get_mask(img):\n",
    "    # Find the mask\n",
    "    mask = predict_mask(img)\n",
    "    # Find the contour of the mask\n",
    "    contour = get_contour(mask)\n",
    "    # Crop the image according to the contour\n",
    "    img = crop_image(img, contour)\n",
    "    return img\n",
    "\n",
    "def get_masked_image(img):\n",
    "    # Find the mask\n",
    "    img = get_mask(img)\n",
    "    img[img == 0] = 0\n",
    "    return img\n",
    "\n",
    "directories = [test_dir, train_dir]\n",
    "for directory in directories:\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = get_masked_image(img)\n",
    "        # Write the image to the results/cropped folder\n",
    "        img_path = os.path.join(cropped_dir, img_name)\n",
    "        cv2.imwrite(img_path, img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[95], line 33\u001B[0m\n\u001B[0;32m     31\u001B[0m mask \u001B[38;5;241m=\u001B[39m get_masked_image(img)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Find the heatmap\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m heatmap \u001B[38;5;241m=\u001B[39m \u001B[43mget_heatmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Write the image to the results/heatmaps folder\u001B[39;00m\n\u001B[0;32m     35\u001B[0m img_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(heatmaps_dir, img_name)\n",
      "Cell \u001B[1;32mIn[95], line 19\u001B[0m, in \u001B[0;36mget_heatmap\u001B[1;34m(img, mask)\u001B[0m\n\u001B[0;32m     17\u001B[0m window \u001B[38;5;241m=\u001B[39m edges_c[y:y\u001B[38;5;241m+\u001B[39mwindow_size, x:x\u001B[38;5;241m+\u001B[39mwindow_size]\n\u001B[0;32m     18\u001B[0m mask_metal_window \u001B[38;5;241m=\u001B[39m mask_metal_c[y:y\u001B[38;5;241m+\u001B[39mwindow_size, x:x\u001B[38;5;241m+\u001B[39mwindow_size]\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask_metal_window\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m mask_metal_window[(\u001B[38;5;28mint\u001B[39m((window_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)), (\u001B[38;5;28mint\u001B[39m((window_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m))] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     20\u001B[0m     heat_map[y:y\u001B[38;5;241m+\u001B[39mwindow_step, x:x\u001B[38;5;241m+\u001B[39mwindow_step] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Create heatmaps of the magnitude of the gradient\n",
    "def get_heatmap(img, mask):# Sliding window over edges image in two dimensions to create a heatmap of the edges\n",
    "    # apply threshold to binarize the image\n",
    "    _, thresh = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
    "    # Apply Gaussian blur\n",
    "    blur = cv2.GaussianBlur(thresh, (13,13), 0)\n",
    "     # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    window_size = 201 # Odd number only\n",
    "    window_step = 10\n",
    "    heat_map = np.zeros_like(edges)\n",
    "    # pad the images with zeros\n",
    "    edges_c = np.pad(edges, int((window_size-1)/2), mode='constant', constant_values=0)\n",
    "    mask_metal_c = np.pad(mask, int((window_size-1)/2), mode='constant', constant_values=0)\n",
    "    for y in range(0, edges_c.shape[0], window_step):\n",
    "        for x in range(0, edges_c.shape[1], window_step):\n",
    "            window = edges_c[y:y+window_size, x:x+window_size]\n",
    "            mask_metal_window = mask_metal_c[y:y+window_size, x:x+window_size]/255\n",
    "            if mask_metal_window.sum() == 0 or mask_metal_window[(int((window_size - 1) / 2)), (int((window_size - 1) / 2))] == 0:\n",
    "                heat_map[y:y+window_step, x:x+window_step] = 0\n",
    "            else:\n",
    "                heat_map[y:y+window_step, x:x+window_step] = np.sum(window)/mask_metal_window.sum()\n",
    "\n",
    "    heat_map = cv2.equalizeHist(heat_map)\n",
    "    return heat_map\n",
    "\n",
    "for img_name in os.listdir(cropped_dir):\n",
    "    img_path = os.path.join(cropped_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    # Find the mask\n",
    "    mask = get_masked_image(img)\n",
    "    # Find the heatmap\n",
    "    heatmap = get_heatmap(img, mask)\n",
    "    # Write the image to the results/heatmaps folder\n",
    "    img_path = os.path.join(heatmaps_dir, img_name)\n",
    "    cv2.imwrite(img_path, heatmap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
