{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the images from the data folder to tensorflow datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 63 images\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Load the dataset from the local folder\n",
    "dataset_url = 'C:/Users/jonat/PycharmProjects/Titanium_Find_Contour_U-Net'\n",
    "\n",
    "# Count the number of images in the dataset\n",
    "images_dir = pathlib.Path('./images')\n",
    "image_count = len(list(images_dir.glob('*.tif')))\n",
    "print(f\"The dataset contains {image_count} images\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train folder contains 50 images\n",
      "The test folder contains 13 images\n"
     ]
    }
   ],
   "source": [
    "# Split the images to train and test folders in the data folder (80% train, 20% test)\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Check if the data folder exists, if not create it\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "\n",
    "# Create the train and test folders\n",
    "if not os.path.exists('./data/train'):\n",
    "    os.makedirs('./data/train')\n",
    "\n",
    "if not os.path.exists('./data/test'):\n",
    "    os.makedirs('./data/test')\n",
    "\n",
    "# Define the train and test folders\n",
    "data_dir = pathlib.Path('./data')\n",
    "train_dir = pathlib.Path('./data/train')\n",
    "test_dir = pathlib.Path('./data/test')\n",
    "\n",
    "# Copy the images from the images folder to the data folder\n",
    "for file in os.listdir(images_dir):\n",
    "    if file.endswith('.tif'):\n",
    "        shutil.copy(os.path.join(images_dir, file), os.path.join(data_dir, file))\n",
    "\n",
    "# Split the images to train and test folders randomly\n",
    "# Seed the random number generator\n",
    "np.random.seed(42)\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.tif'):\n",
    "        if np.random.rand(1) < 0.8:\n",
    "            shutil.move(os.path.join(data_dir, file), os.path.join(train_dir, file))\n",
    "        else:\n",
    "            shutil.move(os.path.join(data_dir, file), os.path.join(test_dir, file))\n",
    "\n",
    "# Count the number of images in the train and test folders\n",
    "train_image_count = len(list(train_dir.glob('*.tif')))\n",
    "test_image_count = len(list(test_dir.glob('*.tif')))\n",
    "print(f\"The train folder contains {train_image_count} images\")\n",
    "print(f\"The test folder contains {test_image_count} images\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Convert the images from TIFF to PNG\n",
    "from PIL import Image\n",
    "\n",
    "# Convert the images in the train folder\n",
    "for file in os.listdir(train_dir):\n",
    "    if file.endswith('.tif'):\n",
    "        tif_image = Image.open(os.path.join(train_dir, file))\n",
    "        # Convert the image to a NumPy array\n",
    "        tif_array = np.array(tif_image)\n",
    "        # Save the NumPy array as a PNG image\n",
    "        jpeg_image = Image.fromarray(tif_array)\n",
    "        jpeg_image.save(os.path.join(train_dir, file.replace('.tif', '.png')), \"PNG\")\n",
    "        tif_image.close()\n",
    "        os.remove(os.path.join(train_dir, file))\n",
    "\n",
    "# Convert the images in the test folder\n",
    "for file in os.listdir(test_dir):\n",
    "    if file.endswith('.tif'):\n",
    "        tif_image = Image.open(os.path.join(test_dir, file))\n",
    "        # Convert the image to a NumPy array\n",
    "        tif_array = np.array(tif_image)\n",
    "        # Save the NumPy array as a PNG image\n",
    "        jpeg_image = Image.fromarray(tif_array)\n",
    "        jpeg_image.save(os.path.join(test_dir, file.replace('.tif', '.png')), \"PNG\")\n",
    "        tif_image.close()\n",
    "        os.remove(os.path.join(test_dir, file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train masks folder contains 50 images\n",
      "The test masks folder contains 13 images\n"
     ]
    }
   ],
   "source": [
    "# Generate the ground truth masks for the train and test datasets\n",
    "# and save it in the masks folder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "measurements_dir = pathlib.Path('./measurments')\n",
    "\n",
    "# Define the masks folder\n",
    "masks_dir = pathlib.Path('./masks')\n",
    "\n",
    "# Check if the masks folder exists, if not create it\n",
    "if not os.path.exists('./masks'):\n",
    "    os.makedirs('./masks')\n",
    "\n",
    "# Create the train and test folders\n",
    "if not os.path.exists('./masks/train'):\n",
    "    os.makedirs('./masks/train')\n",
    "\n",
    "if not os.path.exists('./masks/test'):\n",
    "    os.makedirs('./masks/test')\n",
    "\n",
    "# Define the train and test masks folders\n",
    "train_masks_dir = pathlib.Path('./masks/train')\n",
    "test_masks_dir = pathlib.Path('./masks/test')\n",
    "\n",
    "# Copy the images from the measurements folder to the masks folder\n",
    "for file in os.listdir(measurements_dir):\n",
    "            root, ext = os.path.splitext(file)\n",
    "            if root.title() + \"_01.Tif\" in [fil.title() for fil in os.listdir(images_dir)]:\n",
    "                shutil.copy(os.path.join(measurements_dir, file), os.path.join(masks_dir, file))\n",
    "\n",
    "# Split the images to train and test according to match file names in the train and test folders\n",
    "for file in os.listdir(masks_dir):\n",
    "    root, ext = os.path.splitext(file)\n",
    "    if root.title() + \"_01.Png\" in [fil.title() for fil in os.listdir(train_dir)]:\n",
    "        shutil.move(os.path.join(masks_dir, file), os.path.join(train_masks_dir, file))\n",
    "    elif root.title() + \"_01.Png\" in [fil.title() for fil in os.listdir(test_dir)]:\n",
    "        shutil.move(os.path.join(masks_dir, file), os.path.join(test_masks_dir, file))\n",
    "\n",
    "# # Find in the train and test that don't have a match in the masks folder\n",
    "# for file in os.listdir(train_dir):\n",
    "#     root, ext = os.path.splitext(file)\n",
    "#     if root.title() + \".Png\" not in [ os.path.splitext(fil)[0].title() + \"_01.Png\" for fil in os.listdir(train_masks_dir)]:\n",
    "#         print(file)\n",
    "#         pass\n",
    "\n",
    "# Count the number of images in the train and test masks folders\n",
    "train_mask_count = len(list(train_masks_dir.glob('*.png')))\n",
    "test_mask_count = len(list(test_masks_dir.glob('*.png')))\n",
    "print(f\"The train masks folder contains {train_mask_count} images\")\n",
    "print(f\"The test masks folder contains {test_mask_count} images\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Generate the ground truth masks for the train and test datasets\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def generate_mask_from_yellow_line(file_path: str) -> np.ndarray:\n",
    "    # Define the image path\n",
    "    image_path = file_path\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Error: Could not open or read the image.\")\n",
    "    else:\n",
    "        # Create a copy of the original image\n",
    "        processed_image = image.copy()\n",
    "\n",
    "        # Convert the image to the HSV color space\n",
    "        hsv = cv2.cvtColor(processed_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define the lower and upper bounds for the yellow color in the HSV color space\n",
    "        lower_yellow = np.array([20, 100, 100])\n",
    "        upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "        # Create a mask for the yellow pixels\n",
    "        mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "        # Find the contours in the mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours:\n",
    "            for contour in contours:\n",
    "                # Find the convex hull of each contour\n",
    "                convex_hull = cv2.convexHull(contour)\n",
    "                # Draw the convex hull on the processed image\n",
    "                cv2.drawContours(processed_image, [convex_hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the processed image\n",
    "            # cv2.imshow('Processed Image', processed_image)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            # Create a copy of the processed image for the next step\n",
    "            edges_image = processed_image.copy()\n",
    "\n",
    "            # Apply Canny edge detection\n",
    "            edges = cv2.Canny(edges_image, 400, 600)\n",
    "            kernel = np.ones((2, 2), np.uint8)\n",
    "            edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "            # cv2.imshow('Edges', edges)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            # Find contours in the edges\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            if contours:\n",
    "                # Find the largest contour\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                # Draw the largest contour with a red color (0, 0, 255)\n",
    "                cv2.drawContours(processed_image, [largest_contour], -1, (0, 0, 255), 2)\n",
    "\n",
    "                # Show the final processed image\n",
    "                # cv2.imshow('Processed Image', processed_image)\n",
    "                # cv2.waitKey(0)\n",
    "\n",
    "                # create a contour hull around the largest contour\n",
    "                hull = cv2.convexHull(largest_contour)\n",
    "\n",
    "                # Create a mask which all pixels inside the contour hull are set to 255\n",
    "                mask = np.zeros_like(image)\n",
    "                cv2.fillPoly(mask, [hull], (255, 255, 255))\n",
    "\n",
    "                # return the mask\n",
    "                return mask\n",
    "\n",
    "            else:\n",
    "                print(\"No contours found in the edges.\")\n",
    "\n",
    "        else:\n",
    "            print(\"No yellow region found in the image.\")\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import cv2\n",
    "directories = [train_masks_dir, test_masks_dir, train_dir, test_dir]\n",
    "\n",
    "# Clean all images from the train and test masks and data folders\n",
    "for directory in directories:\n",
    "    for file in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, file))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, width = gray.shape\n",
    "        img = img[0:width, 0:width]\n",
    "        # replace the image with the new one\n",
    "        cv2.imwrite(os.path.join(directory, file), img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Generate the ground truth masks for the train and test datasets\n",
    "mask_directories = [train_masks_dir, test_masks_dir]\n",
    "for directory in mask_directories:\n",
    "    for file in os.listdir(directory):\n",
    "        mask = generate_mask_from_yellow_line(os.path.join(directory, file))\n",
    "        # replace the image with the new one\n",
    "        cv2.imwrite(os.path.join(directory, file), mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Change all files ending with \"_01\" to \"\"\n",
    "for directory in directories:\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('_01.png'):\n",
    "            os.rename(os.path.join(directory, file), os.path.join(directory, file.replace('_01.png', '.png')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Change the reolution of all images in masks dir to 4096x4096\n",
    "for directory in mask_directories:\n",
    "    for file in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, file))\n",
    "        img = cv2.resize(img, (4096, 4096))\n",
    "        # replace the image with the new one\n",
    "        cv2.imwrite(os.path.join(directory, file), img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Convert all images in masks dir to grayscale\n",
    "for directory in directories:\n",
    "    for file in os.listdir(directory):\n",
    "        img = cv2.imread(os.path.join(directory, file))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # replace the image with the new one\n",
    "        cv2.imwrite(os.path.join(directory, file), gray)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
